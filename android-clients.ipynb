{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import ujson as json\n",
    "\n",
    "from moztelemetry import get_pings, get_pings_properties\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of pings from \"saved-session\" to build a set of core client data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update_channel = \"nightly\"\n",
    "now = dt.datetime.now()\n",
    "start = dt.datetime(2016,1,23) #now - dt.timedelta(30)\n",
    "end = dt.datetime(2016,2,24) #now - dt.timedelta(1)\n",
    "\n",
    "pings = get_pings(sc, app=\"Fennec\", channel=update_channel,\n",
    "                  submission_date=(start.strftime(\"%Y%m%d\"), end.strftime(\"%Y%m%d\")),\n",
    "                  build_id=(\"20100101000000\", \"99999999999999\"),\n",
    "                  fraction=1)\n",
    "\n",
    "subset = get_pings_properties(pings, [\"meta/clientId\",\n",
    "                                      \"meta/documentId\",\n",
    "                                      \"meta/submissionDate\",\n",
    "                                      \"application/version\",\n",
    "                                      \"environment/profile/creationDate\",\n",
    "                                      \"environment/system/os/version\",\n",
    "                                      \"environment/system/memoryMB\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the set of pings, make sure we have actual clientIds and remove duplicate pings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dedupe_pings(rdd):\n",
    "    return rdd.filter(lambda p: p[\"meta/clientId\"] is not None)\\\n",
    "              .map(lambda p: (p[\"meta/clientId\"] + p[\"meta/documentId\"], p))\\\n",
    "              .reduceByKey(lambda x, y: x)\\\n",
    "              .map(lambda x: x[1])\n",
    "\n",
    "subset = dedupe_pings(subset)\n",
    "print subset.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the set of pings to one ping per client, using the newest ping as determined by submission date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sort_by_submission(x, y):\n",
    "    xDate = int(x[\"meta/submissionDate\"])\n",
    "    yDate = int(y[\"meta/submissionDate\"])\n",
    "    if xDate > yDate:\n",
    "        return x\n",
    "    return y\n",
    "\n",
    "def reduce_by_client(rdd):\n",
    "    return rdd.map(lambda x: (x[\"meta/clientId\"], x))\\\n",
    "    .reduceByKey(lambda x, y: sort_by_submission(x, y))\\\n",
    "    .map(lambda x: x[1])\n",
    "    \n",
    "reduced = reduce_by_client(subset)\n",
    "reduced.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform and sanitize the pings into arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform(ping):    \n",
    "    clientId = ping[\"meta/clientId\"] # Should not be None since we filter those out\n",
    "\n",
    "    profileDate = None\n",
    "    profileDaynum = ping[\"environment/profile/creationDate\"]\n",
    "    if profileDaynum is not None:\n",
    "        profileDate = (dt.date(1970, 1, 1) + dt.timedelta(int(profileDaynum))).strftime(\"%Y%m%d\")\n",
    "\n",
    "    submissionDate = ping[\"meta/submissionDate\"] # Added via the ingestion process so should not be None\n",
    "\n",
    "    version = ping[\"application/version\"]\n",
    "    os_version = int(ping[\"environment/system/os/version\"])\n",
    "    memory = ping[\"environment/system/memoryMB\"]\n",
    "    if memory is None:\n",
    "        memory = 0\n",
    "    else:\n",
    "        memory = int(memory)\n",
    "            \n",
    "    return [clientId, profileDate, submissionDate, version, os_version, memory]\n",
    "\n",
    "transformed = reduced.map(transform)\n",
    "print transformed.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the data to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grouped = pd.DataFrame(transformed.collect(), columns=[\"clientid\", \"profiledate\", \"submissiondate\", \"version\", \"osversion\", \"memory\"])\n",
    "#!mkdir -p ./output\n",
    "#grouped.to_csv(\"./output/android-clients-\" + update_channel + \"-\" + end.strftime(\"%Y%m%d\") + \".csv\", index=False)\n",
    "\n",
    "s3_output = \"s3n://net-mozaws-prod-us-west-2-pipeline-analysis/mfinkle/android_clients\"\n",
    "s3_output += \"/v1/channel=\" + update_channel + \"/end_date=\" + end.strftime(\"%Y%m%d\") \n",
    "grouped = sqlContext.createDataFrame(transformed, [\"clientid\", \"profiledate\", \"submissiondate\", \"version\", \"osversion\", \"memory\"])\n",
    "grouped.saveAsParquetFile(s3_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
