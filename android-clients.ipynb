{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import ujson as json\n",
    "\n",
    "from moztelemetry import get_pings, get_pings_properties\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of pings from \"saved-session\" to build a set of core client data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update_channel = \"nightly\"\n",
    "now = dt.datetime.now()\n",
    "start = dt.datetime(2016,2,23) #now - dt.timedelta(30)\n",
    "end = dt.datetime(2016,2,28) #now - dt.timedelta(1)\n",
    "\n",
    "pings = get_pings(sc, app=\"Fennec\", channel=update_channel,\n",
    "                  submission_date=(start.strftime(\"%Y%m%d\"), end.strftime(\"%Y%m%d\")),\n",
    "                  build_id=(\"20100101000000\", \"99999999999999\"),\n",
    "                  fraction=1)\n",
    "\n",
    "subset = get_pings_properties(pings, [\"meta/clientId\",\n",
    "                                      \"meta/documentId\",\n",
    "                                      \"meta/submissionDate\",\n",
    "                                      \"creationDate\",\n",
    "                                      \"application/version\",\n",
    "                                      \"environment/system/os/version\",\n",
    "                                      \"environment/profile/creationDate\",\n",
    "                                      \"environment/settings/locale\",\n",
    "                                      \"environment/settings/defaultSearchEngine\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the set of pings, make sure we have actual clientIds and remove duplicate pings. We collect each unique ping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dedupe_pings(rdd):\n",
    "    return rdd.filter(lambda p: p[\"meta/clientId\"] is not None)\\\n",
    "              .map(lambda p: (p[\"meta/clientId\"] + p[\"meta/documentId\"] + p[\"creationDate\"], p))\\\n",
    "              .reduceByKey(lambda x, y: x)\\\n",
    "              .map(lambda x: x[1])\n",
    "\n",
    "subset = dedupe_pings(subset)\n",
    "print subset.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform and sanitize the pings into arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform(ping):\n",
    "    # Should not be None since we filter those out.\n",
    "    clientId = ping[\"meta/clientId\"]\n",
    "\n",
    "    profileDate = None\n",
    "    profileDaynum = ping[\"environment/profile/creationDate\"]\n",
    "    if profileDaynum is not None:\n",
    "        profileDate = dt.date(1970, 1, 1) + dt.timedelta(int(profileDaynum))\n",
    "\n",
    "    creationDate = ping[\"creationDate\"]\n",
    "    if creationDate is not None:\n",
    "        # This is only accurate because we know the creation date is always in 'Z' (zulu) time.\n",
    "        creationDate = dt.datetime.strptime(ping[\"creationDate\"], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "\n",
    "    # Added via the ingestion process so should not be None.\n",
    "    submissionDate = dt.datetime.strptime(ping[\"meta/submissionDate\"], \"%Y%m%d\").date()\n",
    "\n",
    "    version = ping[\"application/version\"]\n",
    "    os_version = int(ping[\"environment/system/os/version\"])\n",
    "    locale = ping[\"environment/settings/locale\"]\n",
    "    defaultSearch = ping[\"environment/settings/defaultSearchEngine\"]\n",
    "\n",
    "    return [clientId, profileDate, submissionDate, creationDate, version, os_version, locale, defaultSearch]\n",
    "\n",
    "transformed = subset.map(transform)\n",
    "print transformed.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the data to CSV or Parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grouped = pd.DataFrame(transformed.collect(), columns=[\"clientid\", \"profiledate\", \"submissiondate\", \"creationdate\", \"appversion\", \"osversion\", \"locale\", \"defaultsearch\"])\n",
    "#!mkdir -p ./output\n",
    "#grouped.to_csv(\"./output/android-clients-\" + update_channel + \"-\" + end.strftime(\"%Y%m%d\") + \".csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "s3_output = \"s3n://net-mozaws-prod-us-west-2-pipeline-analysis/mfinkle/android_clients\"\n",
    "s3_output += \"/v1/channel=\" + update_channel + \"/end_date=\" + end.strftime(\"%Y%m%d\") \n",
    "grouped = sqlContext.createDataFrame(transformed, [\"clientid\", \"profiledate\", \"submissiondate\", \"creationdate\", \"appversion\", \"osversion\", \"locale\", \"defaultsearch\"])\n",
    "grouped.saveAsParquetFile(s3_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
